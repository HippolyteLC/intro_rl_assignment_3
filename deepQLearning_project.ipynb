{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0c69620",
   "metadata": {},
   "source": [
    "**Deep Q Learning Project RL**\n",
    "\n",
    "General Task Description:\n",
    "\n",
    "-> Given a fixed neural network, you will train an agent which will be able to play cartpole V1 on different pole lengths, e.g. make a generalist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987ef14c",
   "metadata": {},
   "source": [
    "1. IMPORT WHAT WE NEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e427690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import gymnasium as gym\n",
    "from collections import deque\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from test_script import QNetwork\n",
    "from test_script import bar_plot, test_pole_length, test_script\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f732c7",
   "metadata": {},
   "source": [
    "2. THE BASE DEEP Q LEARNING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7da7f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replay buffer\n",
    "class ReplayBuffer:\n",
    "    \"\"\"\n",
    "    Replay Buffer to store experience tuples for deep q learning.\n",
    "    The replay buffer stores experiences from many episodes and randomly samples them during training.\n",
    "    \"\"\"\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "\n",
    "def select_action(state, policy_net, epsilon, action_dim):\n",
    "    \"\"\"\n",
    "    Select action using epsilon-greedy policy - did it with epsilon-greedy because of Assignent 1\n",
    "    \"\"\"\n",
    "    if random.random() < epsilon:\n",
    "        return random.randrange(action_dim)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            return q_values.argmax().item()\n",
    "\n",
    "\n",
    "def deep_q_learning(epsilon, gamma, alpha, q_network, n_episodes, \n",
    "                    pole_lengths=None, env_name='CartPole-v1',\n",
    "                    batch_size=64, buffer_capacity=50000, \n",
    "                    update_target_every=10, epsilon_decay=0.995, \n",
    "                    epsilon_min=0.01):\n",
    "    \"\"\"\n",
    "    Deep q learning agent for CartPole-v1 environment with varying pole lengths.\n",
    "    \n",
    "    param: epsilon : float - initial exploration rate\n",
    "    param: gamma : float - discount factor\n",
    "    param: alpha : float - learning rate\n",
    "    param: q_network : QNetwork or None - pre-initialized network or None to create new one\n",
    "    param: n_episodes : int - number of training episodes\n",
    "    param: pole_lengths : array-like or None - array of pole lengths to train on (default: linspace(0.4, 1.8, 30))\n",
    "    param: env_name : str - gym environment name\n",
    "    param: batch_size : int - batch size for training\n",
    "    param: buffer_capacity : int - replay buffer capacity\n",
    "    param: update_target_every : int - how often to update target network\n",
    "    param: epsilon_decay : float - epsilon decay rate per episode\n",
    "    param: epsilon_min : float - minimum epsilon value\n",
    "\n",
    "    return: tuple : (policy_net, target_net, episode_returns)\n",
    "        - trained networks and list of episode rewards\n",
    "    \"\"\"\n",
    "\n",
    "    # initialization of environment\n",
    "    env = gym.make(env_name)\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.n\n",
    "\n",
    "    # initialization of networks if not provided\n",
    "    if q_network is None:\n",
    "        policy_net = QNetwork(state_dim, action_dim)\n",
    "        target_net = QNetwork(state_dim, action_dim)\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "        target_net.eval()\n",
    "    else:\n",
    "        policy_net = q_network\n",
    "        target_net = QNetwork(state_dim, action_dim)\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "        target_net.eval()\n",
    "\n",
    "    # initialization of optimizer\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=alpha)\n",
    "\n",
    "    # initialization of replay buffer\n",
    "    replay_buffer = ReplayBuffer(buffer_capacity)\n",
    "    \n",
    "    # pole lengths for training\n",
    "    if pole_lengths is None:\n",
    "        pole_lengths = np.linspace(0.4, 1.8, 30)\n",
    "\n",
    "    # storing episode returns for plotting\n",
    "    episode_returns = []\n",
    "    \n",
    "    # copy of current epsilon value for decay\n",
    "    epsi = epsilon\n",
    "    \n",
    "    # training loop\n",
    "    for episode in range(n_episodes):\n",
    "        # randomly select pole length for this episode (we need to figure an experimental setup)\n",
    "        pole_length = np.random.choice(pole_lengths)\n",
    "        env.unwrapped.length = pole_length\n",
    "        \n",
    "        # reset environment\n",
    "        state = env.reset()[0]\n",
    "        episode_reward = 0.0\n",
    "        \n",
    "        # epsilon decay\n",
    "        if epsi > epsilon_min:\n",
    "            epsi = max(epsilon_min, epsi * epsilon_decay)\n",
    "        \n",
    "        # episode loop (1 episode = 1 pole length)\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            # select action\n",
    "            action = select_action(state, policy_net, epsi, action_dim)\n",
    "            \n",
    "            # take step\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            # store transition in replay buffer\n",
    "            replay_buffer.push(state, action, reward, next_state, float(done))\n",
    "\n",
    "            # deep q learning update (using mini-batch from replay buffer)\n",
    "            if len(replay_buffer) >= batch_size:\n",
    "                # sample batch from replay buffer\n",
    "                batch = replay_buffer.sample(batch_size)\n",
    "                states, actions, rewards, next_states, dones = zip(*batch)\n",
    "                \n",
    "                # convert to tensors \n",
    "                states_t = torch.FloatTensor(states)\n",
    "                actions_t = torch.LongTensor(actions).unsqueeze(1)\n",
    "                rewards_t = torch.FloatTensor(rewards).unsqueeze(1)\n",
    "                next_states_t = torch.FloatTensor(next_states)\n",
    "                dones_t = torch.FloatTensor(dones).unsqueeze(1)\n",
    "\n",
    "                #get current q values\n",
    "                current_q = policy_net(states_t).gather(1, actions_t)\n",
    "                \n",
    "                # target values\n",
    "                with torch.no_grad():\n",
    "                    next_max = target_net(next_states_t).max(1)[0].unsqueeze(1)\n",
    "                    td_target = rewards_t + gamma * next_max * (1 - dones_t)\n",
    "                \n",
    "                # loss calc\n",
    "                loss = nn.MSELoss()(current_q, td_target)\n",
    "                \n",
    "                # backprop and optimize + gradient clipping\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(policy_net.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            episode_reward += reward\n",
    "            state = next_state\n",
    "        \n",
    "        \n",
    "        #update target network periodically\n",
    "        if episode % update_target_every == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "        #store episode reward\n",
    "        episode_returns.append(episode_reward)\n",
    "        \n",
    "        #only for seeing the progress\n",
    "        if episode % 100 == 0:\n",
    "            avg_reward = np.mean(episode_returns[-100:]) if len(episode_returns) >= 100 else np.mean(episode_returns)\n",
    "            print(f\"Episode {episode}/{n_episodes} | \"\n",
    "                  f\"Avg Reward: {avg_reward:.1f} | \"\n",
    "                  f\"Epsilon: {epsi:.3f}\")\n",
    "    \n",
    "    env.close()\n",
    "    \n",
    "    return (policy_net, target_net, episode_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c3c1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ([0, 0, 0, 0], 1, 1.0, [1, 1, 1, 1], False)\n"
     ]
    }
   ],
   "source": [
    "#Test Replay Buffer\n",
    "# --- IGNORE ---\n",
    "rb=ReplayBuffer(3)\n",
    "rb.push([0,0,0,0], 1, 1.0, [1,1,1,1], False)\n",
    "print(len(rb), rb.sample(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7d8f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0/400 | Avg Reward: 12.0 | Epsilon: 0.980\n",
      "Episode 100/400 | Avg Reward: 126.2 | Epsilon: 0.130\n",
      "Episode 200/400 | Avg Reward: 272.3 | Epsilon: 0.050\n",
      "Episode 300/400 | Avg Reward: 252.0 | Epsilon: 0.050\n",
      "----finished training----\n",
      "Last 3 episode returns: [500.0, 214.0, 500.0]\n"
     ]
    }
   ],
   "source": [
    "#Test the deep q learning function\n",
    "# --- IGNORE ---\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# --- training test ---\n",
    "policy_net, target_net, returns = deep_q_learning(\n",
    "    epsilon=1.0,\n",
    "    gamma=0.99,\n",
    "    alpha=1e-3,\n",
    "    q_network=None,           # create fresh nets\n",
    "    n_episodes=400, \n",
    "    pole_lengths=np.linspace(0.4, 1.2, 5),\n",
    "    env_name='CartPole-v1',\n",
    "    batch_size=32,\n",
    "    buffer_capacity=10000,\n",
    "    update_target_every=5,\n",
    "    epsilon_decay=0.98,\n",
    "    epsilon_min=0.05\n",
    ")\n",
    "\n",
    "print(\"----finished training----\")\n",
    "print(\"Last 3 episode returns:\", returns[-3:] if len(returns) >= 3 else returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b4c126",
   "metadata": {},
   "source": [
    "2.1 Approach 1: Using uniform distribution to sample pole lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a90838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1374d98",
   "metadata": {},
   "source": [
    "2.2 Approach 2: Scrappy Adversial - hitting the weak spots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c7799a",
   "metadata": {},
   "source": [
    "2.2.1 Adaptive curriculum learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a6d036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveCurriculumLearning:\n",
    "    \"\"\" \n",
    "    Adaptive curriculum learning offers an object to store the accumulated rewards, \n",
    "    performances, difficulty socores, and probabilities for each pole length. \n",
    "    We check the last n (LOOK_BACK_WINDOW) rewards a pole has obtained and assign probabilities \n",
    "    to sample each length for an episode. The goal is to attack the policy on its weak spots, \n",
    "    we prioritize training on weak performing lengths. This should shift performance metrics and keeps \n",
    "    our attacks adaptive as we target weakest. \n",
    "    param: all_pole_lengths : numpy.ndarray - stores all the pole lengths\n",
    "    \"\"\"\n",
    "    LOOK_BACK_WINDOW = 20 # we only consider the last 20 rewards a pole has gotten (captures more sensitive information)\n",
    "    P_ADAPTIVE = 0.8 # probability of using adaptive probability distribution or uniform random\n",
    "    def __init__(self, all_pole_lengths):\n",
    "        self.all_pole_lengths = all_pole_lengths\n",
    "        self.rewards = defaultdict(list) # storing pole length episode reward for approach 2 (see 2.2)\n",
    "        self.performances = {} # keep track of performance metric for each pole length \n",
    "        self.difficulty_scores = {} # difficulty_scores\n",
    "        self.distribution = {} # probability distribution for pole lengths to sample from\n",
    "        \n",
    "        # initialize difficulties and probabilities (initially prob is uniform)\n",
    "        initial_prob = 1.0 / len(all_pole_lengths)\n",
    "        self.i_p = initial_prob\n",
    "        for length in all_pole_lengths:\n",
    "            self.difficulty_scores[length] = 1.0\n",
    "            self.distribution[length] = initial_prob\n",
    "\n",
    "    def update_rewards(self, pole_length, reward):\n",
    "        self.rewards[pole_length].append(reward)\n",
    "\n",
    "    def update_performances(self, pole_length):\n",
    "        \"\"\"\n",
    "        Here we update the performance of a pole, \n",
    "        \"\"\"\n",
    "        reward_list = self.rewards[pole_length]\n",
    "\n",
    "        # if a pole has not been played yet, it will be assigned a performance metric of 0\n",
    "        if not reward_list:\n",
    "            metric = 0\n",
    "        else:\n",
    "            # here we use a LOOK BACK WINDOW so that we dont use over-stabilized episode rewards\n",
    "            metric = np.mean(reward_list[-self.LOOK_BACK_WINDOW:])\n",
    "        self.performances[pole_length] = metric\n",
    "\n",
    "    def update_difficulties(self):\n",
    "        \"\"\"\n",
    "        Difficulties are inversely proportional to the performance metrics.\n",
    "        The worse a pole length has performed, the higher the diff score (diff=1 being the worst performing, diff=0 being best).\n",
    "        These require global updates as the update is relative to the totality of pole lengths.\n",
    "        Also normalizing + scaling the values down. Metrics can offer quite larger values otherwise. \n",
    "        \"\"\"\n",
    "        M_max = self.find_max()\n",
    "        M_min = self.find_min()\n",
    "        diff_M = M_max - M_min\n",
    "\n",
    "        # update all difficulty scores with new information\n",
    "        for pole_length, metric in self.performances.items():\n",
    "            if diff_M == 0:\n",
    "                difficulty = 1\n",
    "            else:\n",
    "                difficulty = 1 - ((metric-M_min) / diff_M) # if best perform, diff is 0 >>> probability assignment will be 0\n",
    "            self.difficulty_scores[pole_length] = difficulty\n",
    "    \n",
    "    def update_distribution(self):\n",
    "        \"\"\" \n",
    "        Distribution is also global, here we require an update proportional to the totality. \n",
    "        Normalizing the probabilities (between 0 and 1)\n",
    "        \"\"\"\n",
    "        if not self.difficulty_scores:\n",
    "            return\n",
    "        total_difficulty = sum(self.difficulty_scores.values())\n",
    "\n",
    "        if total_difficulty > 0:\n",
    "            for pole_length, difficulty in self.difficulty_scores.items():\n",
    "                self.distribution[pole_length] = difficulty / total_difficulty\n",
    "        else:\n",
    "            for pole_length in self.all_pole_lengths:\n",
    "                self.distribution[pole_length] = self.i_p\n",
    "    \n",
    "    def sample_length(self):\n",
    "        \"\"\"\n",
    "        Here select the pole length using either uniform or categorical prob distribution. \n",
    "        \"\"\"\n",
    "        if random.random() < self.P_ADAPTIVE:\n",
    "            pole_lengths = list(self.distribution.keys())\n",
    "            probs = list(self.distribution.values())\n",
    "\n",
    "            # if our prob dist is empty, we fallback to uniform selection\n",
    "            if not pole_lengths or sum(probs) == 0:\n",
    "                return np.random.choice(self.all_pole_lengths)\n",
    "            \n",
    "            # selection based on categorical sampling (discrete prob distribution)\n",
    "            return np.random.choice(a=pole_lengths, p=probs, size=1)[0]\n",
    "        else:\n",
    "            return np.random.choice(self.all_pole_lengths)\n",
    "\n",
    "    def find_max(self):\n",
    "        \"\"\"\n",
    "        Find max performing pole length\n",
    "        \"\"\"\n",
    "        if not self.performances:\n",
    "            return 0\n",
    "        return max(self.performances.values())\n",
    "\n",
    "    def find_min(self):\n",
    "        \"\"\"\n",
    "        Find min performing pole length\n",
    "        \"\"\"\n",
    "        if not self.performances:\n",
    "            return 0\n",
    "        return min(self.performances.values())\n",
    "    \n",
    "    def calculate_pole_stats(self):\n",
    "        \"\"\"\n",
    "        Nice display function for avg reward of each pole. Not functionally important at all. \n",
    "        \"\"\"\n",
    "        avg_pole_stats = {}\n",
    "        \n",
    "        for pole_length, rewards_list in self.rewards.items():\n",
    "            # Only process if the list is not empty\n",
    "            if rewards_list:\n",
    "                avg_reward = np.mean(rewards_list)\n",
    "                count = len(rewards_list)\n",
    "            else:\n",
    "                avg_reward = 0.0\n",
    "                count = 0\n",
    "            avg_pole_stats[pole_length] = {\n",
    "                \"average_reward\": avg_reward,\n",
    "                \"episode_count\": count\n",
    "            }\n",
    "        for p, avg in avg_pole_stats.items():\n",
    "            print(f\"Pole length {p} has avg reward {avg}\")\n",
    "        return avg_pole_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bbd394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"\n",
    "    Replay Buffer to store experience tuples for deep q learning.\n",
    "    The replay buffer stores experiences from many episodes and randomly samples them during training.\n",
    "    \"\"\"\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "\n",
    "def select_action(state, policy_net, epsilon, action_dim):\n",
    "    \"\"\"\n",
    "    Select action using epsilon-greedy policy - did it with epsilon-greedy because of Assignent 1\n",
    "    \"\"\"\n",
    "    if random.random() < epsilon:\n",
    "        return random.randrange(action_dim)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            return q_values.argmax().item()\n",
    "\n",
    "\n",
    "def deep_q_learning(epsilon, gamma, alpha, q_network, n_episodes,\n",
    "                    uniform_episode_training_cap=300,\n",
    "                    pole_lengths=None, env_name='CartPole-v1',\n",
    "                    batch_size=64, buffer_capacity=50000, \n",
    "                    update_target_every=10, epsilon_decay=0.995, \n",
    "                    epsilon_min=0.01):\n",
    "    \"\"\"\n",
    "    Deep q learning agent for CartPole-v1 environment with varying pole lengths.\n",
    "    \n",
    "    param: epsilon : float - initial exploration rate\n",
    "    param: gamma : float - discount factor\n",
    "    param: alpha : float - learning rate\n",
    "    param: q_network : QNetwork or None - pre-initialized network or None to create new one\n",
    "    param: n_episodes : int - number of training episodes\n",
    "    param: uniform_episode_training_cap : int - number episodes trained with uniform length selection\n",
    "    param: p_adaptive : float - probability to select pole length from sample distribution, after uniform_episode_training_cap\n",
    "    param: lb_window : int - look back window used to compute performance metric, number of recent pole length performances\n",
    "    param: pole_lengths : array-like or None - array of pole lengths to train on (default: linspace(0.4, 1.8, 30))\n",
    "    param: env_name : str - gym environment name\n",
    "    param: batch_size : int - batch size for training\n",
    "    param: buffer_capacity : int - replay buffer capacity\n",
    "    param: update_target_every : int - how often to update target network\n",
    "    param: epsilon_decay : float - epsilon decay rate per episode\n",
    "    param: epsilon_min : float - minimum epsilon value\n",
    "\n",
    "    return: tuple : (policy_net, target_net, episode_returns)\n",
    "        - trained networks and list of episode rewards\n",
    "    \"\"\"\n",
    "\n",
    "    # initialization of environment\n",
    "    env = gym.make(env_name)\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.n\n",
    "\n",
    "    # initialization of networks if not provided\n",
    "    if q_network is None:\n",
    "        policy_net = QNetwork(state_dim, action_dim)\n",
    "        target_net = QNetwork(state_dim, action_dim)\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "        target_net.eval()\n",
    "    else:\n",
    "        policy_net = q_network\n",
    "        target_net = QNetwork(state_dim, action_dim)\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "        target_net.eval()\n",
    "\n",
    "    # initialization of optimizer\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=alpha)\n",
    "\n",
    "    # initialization of replay buffer\n",
    "    replay_buffer = ReplayBuffer(buffer_capacity)\n",
    "    \n",
    "    # pole lengths for training\n",
    "    if pole_lengths is None:\n",
    "        pole_lengths = np.linspace(0.4, 1.8, 30)\n",
    "\n",
    "    # storing episode returns for plotting\n",
    "    episode_returns = []\n",
    "\n",
    "    # initialize the acl class for adaptive hyperparametre sampling\n",
    "    acl = AdaptiveCurriculumLearning(pole_lengths)\n",
    "\n",
    "    # copy of current epsilon value for decay\n",
    "    epsi = epsilon\n",
    "    \n",
    "    # training loop\n",
    "    for episode in range(n_episodes):\n",
    "        # if current episode is below the uniform_episode_training_cap we select from a uniform distr\n",
    "        if episode < uniform_episode_training_cap:\n",
    "            pole_length = np.random.choice(pole_lengths)\n",
    "        # else use adaptive probability distrubition \n",
    "        else: \n",
    "            pole_length = acl.sample_length()\n",
    "\n",
    "        env.unwrapped.length = pole_length\n",
    "        \n",
    "        # reset environment\n",
    "        state = env.reset()[0]\n",
    "        episode_reward = 0.0\n",
    "        \n",
    "        # epsilon decay\n",
    "        if epsi > epsilon_min:\n",
    "            epsi = max(epsilon_min, epsi * epsilon_decay)\n",
    "        \n",
    "        # episode loop (1 episode = 1 pole length)\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            # select action\n",
    "            action = select_action(state, policy_net, epsi, action_dim)\n",
    "            \n",
    "            # take step\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            # store transition in replay buffer\n",
    "            replay_buffer.push(state, action, reward, next_state, float(done))\n",
    "\n",
    "            # deep q learning update (using mini-batch from replay buffer)\n",
    "            if len(replay_buffer) >= batch_size:\n",
    "                # sample batch from replay buffer\n",
    "                batch = replay_buffer.sample(batch_size)\n",
    "                states, actions, rewards, next_states, dones = zip(*batch)\n",
    "                \n",
    "                # convert to tensors \n",
    "                states_t = torch.FloatTensor(states)\n",
    "                actions_t = torch.LongTensor(actions).unsqueeze(1)\n",
    "                rewards_t = torch.FloatTensor(rewards).unsqueeze(1)\n",
    "                next_states_t = torch.FloatTensor(next_states)\n",
    "                dones_t = torch.FloatTensor(dones).unsqueeze(1)\n",
    "\n",
    "                #get current q values\n",
    "                current_q = policy_net(states_t).gather(1, actions_t)\n",
    "                \n",
    "                # target values\n",
    "                with torch.no_grad():\n",
    "                    next_max = target_net(next_states_t).max(1)[0].unsqueeze(1)\n",
    "                    td_target = rewards_t + gamma * next_max * (1 - dones_t)\n",
    "                \n",
    "                # loss calc\n",
    "                loss = nn.MSELoss()(current_q, td_target)\n",
    "                \n",
    "                # backprop and optimize + gradient clipping\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(policy_net.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            episode_reward += reward\n",
    "            state = next_state\n",
    "        \n",
    "        \n",
    "        #update target network periodically\n",
    "        if episode % update_target_every == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "        #store episode reward\n",
    "        episode_returns.append(episode_reward)\n",
    "\n",
    "        # update acl for rewards, performance metrics, scores, and probs\n",
    "        # difficulty scores and probabilities are global updates, can be seen in the respective update methods\n",
    "        acl.update_rewards(pole_length, episode_reward)\n",
    "        if episode >= uniform_episode_training_cap:\n",
    "            acl.update_performances(pole_length)\n",
    "            acl.update_difficulties()\n",
    "            acl.update_distribution()\n",
    "\n",
    "        #only for seeing the progress\n",
    "        if episode % 50 == 0:\n",
    "            avg_reward = np.mean(episode_returns[-100:]) if len(episode_returns) >= 100 else np.mean(episode_returns)\n",
    "            print(f\"Episode {episode}/{n_episodes} | \"\n",
    "                  f\"Avg Reward: {avg_reward:.1f} | \"\n",
    "                  f\"Epsilon: {epsi:.3f} | \"\n",
    "                  f\"Probability Distribution{acl.distribution} | \\n\" \n",
    "                  f\"Pole Length Performances{acl.performances} | \\n\"\n",
    "                  )\n",
    "            \n",
    "    \n",
    "    env.close()\n",
    "    \n",
    "    return policy_net, target_net, episode_returns, acl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa06100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0/200 | Avg Reward: 12.0 | Epsilon: 0.980 | {np.float64(0.4): 0.2, np.float64(0.6): 0.2, np.float64(0.8): 0.2, np.float64(1.0): 0.2, np.float64(1.2): 0.2} | \n",
      "{} | \n",
      "\n",
      "Episode 50/200 | Avg Reward: 59.7 | Epsilon: 0.357 | {np.float64(0.4): 0.2, np.float64(0.6): 0.2, np.float64(0.8): 0.2, np.float64(1.0): 0.2, np.float64(1.2): 0.2} | \n",
      "{} | \n",
      "\n",
      "Episode 100/200 | Avg Reward: 107.6 | Epsilon: 0.130 | {np.float64(0.4): 0.2, np.float64(0.6): 0.2, np.float64(0.8): 0.2, np.float64(1.0): 0.2, np.float64(1.2): 0.2} | \n",
      "{np.float64(1.0): np.float64(76.96296296296296)} | \n",
      "\n",
      "Episode 150/200 | Avg Reward: 152.8 | Epsilon: 0.050 | {np.float64(0.4): np.float64(0.0757035944309186), np.float64(0.6): np.float64(0.0), np.float64(0.8): np.float64(0.3440014099438963), np.float64(1.0): np.float64(0.4083047284174575), np.float64(1.2): np.float64(0.17199026720772756)} | \n",
      "{np.float64(1.0): np.float64(105.02272727272727), np.float64(1.2): np.float64(127.34482758620689), np.float64(0.8): np.float64(111.09677419354838), np.float64(0.6): np.float64(143.5909090909091), np.float64(0.4): np.float64(136.44)} | \n",
      "\n",
      "----finished training----\n",
      "Last 3 episode returns: [137.0, 111.0, 121.0]\n"
     ]
    }
   ],
   "source": [
    "#Test the deep q learning function\n",
    "# --- IGNORE ---\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# --- training test ---\n",
    "policy_net, target_net, returns, acl = deep_q_learning(\n",
    "    epsilon=1.0,\n",
    "    gamma=0.99,\n",
    "    alpha=1e-3,\n",
    "    q_network=None,           # create fresh nets\n",
    "    n_episodes=200, \n",
    "    uniform_episode_training_cap=100, # here you set the moment from which adaptive CL is applied \n",
    "    pole_lengths=np.linspace(0.4, 1.2, 5),\n",
    "    env_name='CartPole-v1',\n",
    "    batch_size=32,\n",
    "    buffer_capacity=10000,\n",
    "    update_target_every=5,\n",
    "    epsilon_decay=0.98,\n",
    "    epsilon_min=0.05\n",
    ")\n",
    "\n",
    "print(\"----finished training----\")\n",
    "print(\"Last 3 episode returns:\", returns[-3:] if len(returns) >= 3 else returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef8394d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "{np.float64(1.0): np.float64(106.85483870967742), np.float64(1.2): np.float64(127.03030303030303), np.float64(0.8): np.float64(113.90196078431373), np.float64(0.6): np.float64(141.52173913043478), np.float64(0.4): np.float64(133.3548387096774)}\n",
      "{np.float64(0.4): np.float64(0.2355820774754731), np.float64(0.6): np.float64(0.0), np.float64(0.8): np.float64(0.7967190031671615), np.float64(1.0): np.float64(1.0), np.float64(1.2): np.float64(0.4180193765305529)}\n",
      "{np.float64(0.4): np.float64(0.09614337454752851), np.float64(0.6): np.float64(0.0), np.float64(0.8): np.float64(0.32514890076308484), np.float64(1.0): np.float64(0.4081098850040415), np.float64(1.2): np.float64(0.17059783968534506)}\n"
     ]
    }
   ],
   "source": [
    "# acl.calculate_pole_stats()\n",
    "print(type(acl.all_pole_lengths))\n",
    "print(acl.performances)\n",
    "print(acl.difficulty_scores)\n",
    "print(acl.distribution)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "8db0ea50",
   "metadata": {},
   "source": [
    "2.3 Approach 3: Training on the least visited pole lengths\n",
    "\n",
    "Description of difference in implementation (used claude to get the table)\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781dd72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplorationDiversityCurriculum:\n",
    "    \"\"\" \n",
    "    Exploration Diversity Curriculum prioritizes pole lengths that have been visited LEAST.\n",
    "    This ensures balanced coverage of the pole length space and prevents over-training\n",
    "    on familiar lengths while neglecting others.\n",
    "    \n",
    "    basically saying \"Explore what you haven't seen\"\n",
    "    \n",
    "    param: all_pole_lengths : numpy.ndarray - stores all the pole lengths\n",
    "    \"\"\"\n",
    "    \n",
    "    P_ADAPTIVE = 0.8  #probability of using adaptive (exploration-based) vs uniform\n",
    "    MIN_VISITS_THRESHOLD = 10  #minimum visits before a length is considered \"explored\"\n",
    "    \n",
    "    def __init__(self, all_pole_lengths):\n",
    "        self.all_pole_lengths = all_pole_lengths\n",
    "        self.visit_counts = defaultdict(int)  # track how many times each length was visited\n",
    "        self.rewards = defaultdict(list) \n",
    "        self.rarity_scores = {}  # how \"rare\" each pole length is (inverse of visits)\n",
    "        self.distribution = {}  # probability distribution for sampling\n",
    "        \n",
    "        #initialize with uniform distribution\n",
    "        initial_prob = 1.0 / len(all_pole_lengths)\n",
    "        self.initial_prob = initial_prob\n",
    "        for length in all_pole_lengths:\n",
    "            self.rarity_scores[length] = 1.0\n",
    "            self.distribution[length] = initial_prob\n",
    "    \n",
    "    def update_visit(self, pole_length):\n",
    "        \"\"\"\n",
    "        Increment visit counter for pole length\n",
    "        \"\"\"\n",
    "        self.visit_counts[pole_length] += 1\n",
    "    \n",
    "    def update_rewards(self, pole_length, reward):\n",
    "        \"\"\"\n",
    "        Track rewards (for analysis purposes)\n",
    "        \"\"\"\n",
    "        self.rewards[pole_length].append(reward)\n",
    "    \n",
    "    def update_rarity_scores(self):\n",
    "        \"\"\"\n",
    "        Rarity scores are INVERSELY proportional to visit counts.\n",
    "        Least visited = highest rarity = highest sampling probability\n",
    "        \n",
    "        This creates an exploration bonus for under-explored pole lengths.\n",
    "        \"\"\"\n",
    "        if not self.visit_counts:\n",
    "            return\n",
    "        \n",
    "        max_visits = max(self.visit_counts.values())\n",
    "        min_visits = min(self.visit_counts.values())\n",
    "        diff_visits = max_visits - min_visits\n",
    "        \n",
    "        for pole_length in self.all_pole_lengths:\n",
    "            visits = self.visit_counts.get(pole_length, 0)\n",
    "            \n",
    "            if diff_visits == 0:\n",
    "                #all lengths visited equally - uniform rarity\n",
    "                rarity = 1.0\n",
    "            else:\n",
    "                #inverse normalization: least visited = highest rarity (closer to 1)\n",
    "                #most visited = lowest rarity (closer to 0)\n",
    "                rarity = 1.0 - ((visits - min_visits) / diff_visits)\n",
    "            \n",
    "            #add bonus for completely unvisited lengths\n",
    "            if visits == 0:\n",
    "                rarity = 2.0  #double rarity - ultra rare\n",
    "            \n",
    "            self.rarity_scores[pole_length] = rarity\n",
    "    \n",
    "    def update_distribution(self):\n",
    "        \"\"\"\n",
    "        Update sampling distribution based on rarity scores.\n",
    "        Normalize probabilities to sum to 1.\n",
    "        \"\"\"\n",
    "        if not self.rarity_scores:\n",
    "            return\n",
    "        \n",
    "        total_rarity = sum(self.rarity_scores.values())\n",
    "        \n",
    "        if total_rarity > 0:\n",
    "            for pole_length, rarity in self.rarity_scores.items():\n",
    "                self.distribution[pole_length] = rarity / total_rarity\n",
    "        else:\n",
    "            #fallback to uniform\n",
    "            for pole_length in self.all_pole_lengths:\n",
    "                self.distribution[pole_length] = self.initial_prob\n",
    "    \n",
    "    def sample_length(self):\n",
    "        \"\"\"\n",
    "        Sample pole length using either:\n",
    "        - Adaptive (exploration-based) distribution (P_ADAPTIVE probability)\n",
    "        - Uniform random (1 - P_ADAPTIVE probability)\n",
    "        \"\"\"\n",
    "        if random.random() < self.P_ADAPTIVE:\n",
    "            pole_lengths = list(self.distribution.keys())\n",
    "            probs = list(self.distribution.values())\n",
    "            \n",
    "            #fallback to uniform if distribution is invalid\n",
    "            if not pole_lengths or sum(probs) == 0:\n",
    "                return np.random.choice(self.all_pole_lengths)\n",
    "            \n",
    "            #sample based on rarity (exploration priority)\n",
    "            return np.random.choice(a=pole_lengths, p=probs, size=1)[0]\n",
    "        else:\n",
    "            return np.random.choice(self.all_pole_lengths)\n",
    "    \n",
    "    def get_exploration_stats(self):\n",
    "        \"\"\"\n",
    "        Return statistics about exploration coverage\n",
    "        \"\"\"\n",
    "        total_visits = sum(self.visit_counts.values())\n",
    "        unvisited = [l for l in self.all_pole_lengths if self.visit_counts[l] == 0]\n",
    "        under_explored = [l for l in self.all_pole_lengths \n",
    "                         if 0 < self.visit_counts[l] < self.MIN_VISITS_THRESHOLD]\n",
    "        \n",
    "        return {\n",
    "            'total_visits': total_visits,\n",
    "            'unvisited_count': len(unvisited),\n",
    "            'under_explored_count': len(under_explored),\n",
    "            'visit_counts': dict(self.visit_counts),\n",
    "            'min_visits': min(self.visit_counts.values()) if self.visit_counts else 0,\n",
    "            'max_visits': max(self.visit_counts.values()) if self.visit_counts else 0,\n",
    "        }\n",
    "    \n",
    "    def calculate_pole_stats(self):\n",
    "        \"\"\"\n",
    "        Display statistics for each pole length\n",
    "        \"\"\"\n",
    "        stats = {}\n",
    "        \n",
    "        for pole_length in self.all_pole_lengths:\n",
    "            visits = self.visit_counts.get(pole_length, 0)\n",
    "            rewards_list = self.rewards.get(pole_length, [])\n",
    "            \n",
    "            if rewards_list:\n",
    "                avg_reward = np.mean(rewards_list)\n",
    "            else:\n",
    "                avg_reward = 0.0\n",
    "            \n",
    "            stats[pole_length] = {\n",
    "                \"visits\": visits,\n",
    "                \"average_reward\": avg_reward,\n",
    "                \"rarity_score\": self.rarity_scores.get(pole_length, 1.0),\n",
    "                \"sampling_prob\": self.distribution.get(pole_length, self.initial_prob)\n",
    "            }\n",
    "        \n",
    "        return stats\n",
    "\n",
    "\n",
    "def select_action(state, policy_net, epsilon, action_dim):\n",
    "    \"\"\"\n",
    "    Select action using epsilon-greedy policy\n",
    "    \"\"\"\n",
    "    if random.random() < epsilon:\n",
    "        return random.randrange(action_dim)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "            q_values = policy_net(state_tensor)\n",
    "            return q_values.argmax().item()\n",
    "\n",
    "\n",
    "def deep_q_learning_exploration_diversity(\n",
    "        epsilon, gamma, alpha, q_network, n_episodes,\n",
    "        uniform_episode_training_cap=300,\n",
    "        pole_lengths=None, env_name='CartPole-v1',\n",
    "        batch_size=64, buffer_capacity=50000, \n",
    "        update_target_every=10, epsilon_decay=0.995, \n",
    "        epsilon_min=0.01):\n",
    "    \"\"\"\n",
    "    Deep q learning with Exploration Diversity Curriculum\n",
    "    \n",
    "    This strategy prioritizes training on LEAST-VISITED pole lengths\n",
    "    \n",
    "    param: epsilon : float - initial exploration rate\n",
    "    param: gamma : float - discount factor\n",
    "    param: alpha : float - learning rate\n",
    "    param: q_network : QNetwork or None - pre-initialized network or None to create new one\n",
    "    param: n_episodes : int - number of training episodes\n",
    "    param: uniform_episode_training_cap : int - number episodes trained with uniform length selection\n",
    "    param: p_adaptive : float - probability to select pole length from sample distribution, after uniform_episode_training_cap\n",
    "    param: lb_window : int - look back window used to compute performance metric, number of recent pole length performances\n",
    "    param: pole_lengths : array-like or None - array of pole lengths to train on (default: linspace(0.4, 1.8, 30))\n",
    "    param: env_name : str - gym environment name\n",
    "    param: batch_size : int - batch size for training\n",
    "    param: buffer_capacity : int - replay buffer capacity\n",
    "    param: update_target_every : int - how often to update target network\n",
    "    param: epsilon_decay : float - epsilon decay rate per episode\n",
    "    param: epsilon_min : float - minimum epsilon value\n",
    "    \n",
    "    return: tuple : (policy_net, target_net, episode_returns, exploration_diversity_curriculum)\n",
    "        - trained networks and list of episode rewards\n",
    "    \"\"\"\n",
    "    \n",
    "    #initialize environment\n",
    "    env = gym.make(env_name)\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.n\n",
    "    \n",
    "    #initialize networks\n",
    "    if q_network is None:\n",
    "        policy_net = QNetwork(state_dim, action_dim)\n",
    "        target_net = QNetwork(state_dim, action_dim)\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "        target_net.eval()\n",
    "    else:\n",
    "        policy_net = q_network\n",
    "        target_net = QNetwork(state_dim, action_dim)\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "        target_net.eval()\n",
    "    \n",
    "    #initialize optimizer\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=alpha)\n",
    "    \n",
    "    #initialize replay buffer\n",
    "    replay_buffer = ReplayBuffer(buffer_capacity)\n",
    "    \n",
    "    #pole lengths for training\n",
    "    if pole_lengths is None:\n",
    "        pole_lengths = np.linspace(0.4, 1.8, 30)\n",
    "    \n",
    "    #storing episode returns\n",
    "    episode_returns = []\n",
    "    \n",
    "    #initialize Exploration Diversity Curriculum\n",
    "    exploration_diversity_curriculum = ExplorationDiversityCurriculum(pole_lengths)\n",
    "    \n",
    "    #epsilon copy\n",
    "    epsi = epsilon\n",
    "    \n",
    "    #training loop\n",
    "    for episode in range(n_episodes):\n",
    "        #phase 1: uniform sampling for initial exploration\n",
    "        if episode < uniform_episode_training_cap:\n",
    "            pole_length = np.random.choice(pole_lengths)\n",
    "        #phase 2: prioritize least-visited lengths\n",
    "        else:\n",
    "            pole_length = exploration_diversity_curriculum.sample_length()\n",
    "        \n",
    "        env.unwrapped.length = pole_length\n",
    "        \n",
    "        #track that we visited this length\n",
    "        exploration_diversity_curriculum.update_visit(pole_length)\n",
    "        \n",
    "        #reset environment\n",
    "        state = env.reset()[0]\n",
    "        episode_reward = 0.0\n",
    "        \n",
    "        #epsilon decay\n",
    "        if epsi > epsilon_min:\n",
    "            epsi = max(epsilon_min, epsi * epsilon_decay)\n",
    "        \n",
    "        #episode loop\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            #select action\n",
    "            action = select_action(state, policy_net, epsi, action_dim)\n",
    "            \n",
    "            #take step\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            \n",
    "            #store transition\n",
    "            replay_buffer.push(state, action, reward, next_state, float(done))\n",
    "            \n",
    "            #training step\n",
    "            if len(replay_buffer) >= batch_size:\n",
    "                batch = replay_buffer.sample(batch_size)\n",
    "                states, actions, rewards, next_states, dones = zip(*batch)\n",
    "                \n",
    "                states_t = torch.FloatTensor(states)\n",
    "                actions_t = torch.LongTensor(actions).unsqueeze(1)\n",
    "                rewards_t = torch.FloatTensor(rewards).unsqueeze(1)\n",
    "                next_states_t = torch.FloatTensor(next_states)\n",
    "                dones_t = torch.FloatTensor(dones).unsqueeze(1)\n",
    "                \n",
    "                current_q = policy_net(states_t).gather(1, actions_t)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    next_max = target_net(next_states_t).max(1)[0].unsqueeze(1)\n",
    "                    td_target = rewards_t + gamma * next_max * (1 - dones_t)\n",
    "                \n",
    "                loss = nn.MSELoss()(current_q, td_target)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(policy_net.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            episode_reward += reward\n",
    "            state = next_state\n",
    "        \n",
    "        #update target network periodically\n",
    "        if episode % update_target_every == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "        \n",
    "        #store episode return\n",
    "        episode_returns.append(episode_reward)\n",
    "        \n",
    "        #update curriculum: track rewards and update rarity-based distribution\n",
    "        exploration_diversity_curriculum.update_rewards(pole_length, episode_reward)\n",
    "        \n",
    "        if episode >= uniform_episode_training_cap:\n",
    "            exploration_diversity_curriculum.update_rarity_scores()\n",
    "            exploration_diversity_curriculum.update_distribution()\n",
    "\n",
    "        #progress logging\n",
    "        if episode % 50 == 0:\n",
    "            avg_reward = np.mean(episode_returns[-100:]) if len(episode_returns) >= 100 else np.mean(episode_returns)\n",
    "            exploration_stats = exploration_diversity_curriculum.get_exploration_stats()\n",
    "\n",
    "            print(f\"Episode {episode}/{n_episodes} | \"\n",
    "                  f\"Avg Reward: {avg_reward:.1f} | \"\n",
    "                  f\"Epsilon: {epsi:.3f}\")\n",
    "            print(f\"  Exploration Stats: Unvisited={exploration_stats['unvisited_count']}, \"\n",
    "                  f\"Min visits={exploration_stats['min_visits']}, \"\n",
    "                  f\"Max visits={exploration_stats['max_visits']}\")\n",
    "            \n",
    "            #show top 3 most likely to be sampled (least visited)\n",
    "            top_3_rare = sorted(exploration_diversity_curriculum.distribution.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "            print(f\"  Prioritizing (least visited): {[f'{l:.2f}({p:.3f})' for l, p in top_3_rare]}\")\n",
    "    \n",
    "    env.close()\n",
    "\n",
    "    #am returning also the policy in case we want to save it to test later \n",
    "    return policy_net, target_net, episode_returns, exploration_diversity_curriculum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c978c5",
   "metadata": {},
   "source": [
    "Test the thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cb89be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0/500 | Avg Reward: 16.0 | Epsilon: 0.980\n",
      "  Exploration Stats: Unvisited=4, Min visits=0, Max visits=1\n",
      "  Prioritizing (least visited): ['0.40(0.200)', '0.60(0.200)', '0.80(0.200)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Teodora\\AppData\\Local\\Temp\\ipykernel_8564\\3387781163.py:274: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:256.)\n",
      "  states_t = torch.FloatTensor(states)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50/500 | Avg Reward: 42.5 | Epsilon: 0.357\n",
      "  Exploration Stats: Unvisited=0, Min visits=7, Max visits=14\n",
      "  Prioritizing (least visited): ['0.40(0.200)', '0.60(0.200)', '0.80(0.200)']\n",
      "Episode 100/500 | Avg Reward: 88.6 | Epsilon: 0.130\n",
      "  Exploration Stats: Unvisited=0, Min visits=16, Max visits=27\n",
      "  Prioritizing (least visited): ['0.80(0.324)', '0.40(0.265)', '1.20(0.235)']\n",
      "Episode 150/500 | Avg Reward: 137.5 | Epsilon: 0.050\n",
      "  Exploration Stats: Unvisited=0, Min visits=30, Max visits=31\n",
      "  Prioritizing (least visited): ['0.40(0.250)', '0.60(0.250)', '1.00(0.250)']\n",
      "Episode 200/500 | Avg Reward: 148.0 | Epsilon: 0.050\n",
      "  Exploration Stats: Unvisited=0, Min visits=40, Max visits=41\n",
      "  Prioritizing (least visited): ['0.40(0.250)', '0.60(0.250)', '0.80(0.250)']\n",
      "Episode 250/500 | Avg Reward: 143.2 | Epsilon: 0.050\n",
      "  Exploration Stats: Unvisited=0, Min visits=50, Max visits=51\n",
      "  Prioritizing (least visited): ['0.40(0.250)', '0.60(0.250)', '1.00(0.250)']\n",
      "Episode 300/500 | Avg Reward: 142.2 | Epsilon: 0.050\n",
      "  Exploration Stats: Unvisited=0, Min visits=59, Max visits=61\n",
      "  Prioritizing (least visited): ['1.00(0.500)', '0.60(0.250)', '0.80(0.250)']\n",
      "Episode 350/500 | Avg Reward: 153.2 | Epsilon: 0.050\n",
      "  Exploration Stats: Unvisited=0, Min visits=69, Max visits=71\n",
      "  Prioritizing (least visited): ['1.00(0.500)', '1.20(0.500)', '0.40(0.000)']\n",
      "Episode 400/500 | Avg Reward: 166.8 | Epsilon: 0.050\n",
      "  Exploration Stats: Unvisited=0, Min visits=80, Max visits=81\n",
      "  Prioritizing (least visited): ['0.40(0.250)', '0.80(0.250)', '1.00(0.250)']\n",
      "Episode 450/500 | Avg Reward: 225.4 | Epsilon: 0.050\n",
      "  Exploration Stats: Unvisited=0, Min visits=90, Max visits=91\n",
      "  Prioritizing (least visited): ['0.40(0.250)', '0.60(0.250)', '0.80(0.250)']\n",
      "----finished training----\n",
      "Last 3 episode returns: [500.0, 500.0, 500.0]\n",
      "\n",
      "======================================================================\n",
      "FINAL EXPLORATION STATISTICS\n",
      "======================================================================\n",
      "\n",
      "Pole Length Statistics (sorted by visits):\n",
      "\n",
      "Pole Length  Visits   Avg Reward   Rarity     Prob      \n",
      "----------------------------------------------------------------------\n",
      "1.20         99       147.2        1.000      0.4000    \n",
      "0.40         100      191.8        0.500      0.2000    \n",
      "0.80         100      166.1        0.500      0.2000    \n",
      "1.00         100      146.3        0.500      0.2000    \n",
      "0.60         101      167.9        0.000      0.0000    \n"
     ]
    }
   ],
   "source": [
    "#Test the deep q learning function\n",
    "# --- IGNORE ---\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# --- training test ---\n",
    "policy_net, target_net, returns, exploration_diversity_curriculum = deep_q_learning_exploration_diversity(\n",
    "    epsilon=1.0,\n",
    "    gamma=0.99,\n",
    "    alpha=1e-3,\n",
    "    q_network=None,           # create fresh nets\n",
    "    n_episodes=500, \n",
    "    uniform_episode_training_cap=100, # here you set the moment from which exploration diversity is applied\n",
    "    pole_lengths=np.linspace(0.4, 1.2, 5),\n",
    "    env_name='CartPole-v1',\n",
    "    batch_size=32,\n",
    "    buffer_capacity=10000,\n",
    "    update_target_every=5,\n",
    "    epsilon_decay=0.98,\n",
    "    epsilon_min=0.05\n",
    ")\n",
    "\n",
    "print(\"----finished training----\")\n",
    "print(\"Last 3 episode returns:\", returns[-3:] if len(returns) >= 3 else returns)\n",
    "\n",
    "# Display final statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL EXPLORATION STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "final_stats = exploration_diversity_curriculum.calculate_pole_stats()\n",
    "\n",
    "print(\"\\nPole Length Statistics (sorted by visits):\")\n",
    "sorted_stats = sorted(final_stats.items(), key=lambda x: x[1]['visits'])\n",
    "\n",
    "print(f\"\\n{'Pole Length':<12} {'Visits':<8} {'Avg Reward':<12} {'Rarity':<10} {'Prob':<10}\")\n",
    "print(\"-\"*70)\n",
    "for pole_length, stats in sorted_stats:\n",
    "    print(f\"{pole_length:<12.2f} {stats['visits']:<8} \"\n",
    "            f\"{stats['average_reward']:<12.1f} \"\n",
    "              f\"{stats['rarity_score']:<10.3f} \"\n",
    "              f\"{stats['sampling_prob']:<10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb112434",
   "metadata": {},
   "source": [
    "3. MAIN TRAINING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437483ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88137ab5",
   "metadata": {},
   "source": [
    "4. TESTING BUT JUST FOR US - not using test_script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7451c580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47c7bc6e",
   "metadata": {},
   "source": [
    "5. MAIN EXECUTION WITH PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25e55ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
